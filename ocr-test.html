<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live OCR</title>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
    <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
    <style>
        body {
            font-family: sans-serif;
            text-align: center;
            padding: 10px;
            font-size: 1.2rem;
        }

        video {
            width: 100%;
            max-width: 480px;
            border: 1px solid #ccc;
            border-radius: 8px;
        }


        textarea {
            width: 100%;
            height: 140px;
            margin-top: 12px;
            padding: 10px;
            font-size: 1rem;
            border-radius: 6px;
            box-sizing: border-box;
        }

        .buttons {
            margin-top: 12px;
            display: flex;
            justify-content: center;
            gap: 12px;
            flex-wrap: wrap;
        }

        button {
            padding: 12px 20px;
            font-size: 1rem;
            border-radius: 6px;
            border: none;
            background-color: #007BFF;
            color: white;
            cursor: pointer;
        }

        button:hover {
            background-color: #0056b3;
        }

        #internalCanvas {
            display: none;
        }

        #processedCanvas {
            margin-top: 12px;
            border: 1px solid #888;
            border-radius: 6px;
            display: block;
            width: 100%;
            max-width: 480px;
            height: auto;
        }
    </style>
</head>

<body>
    <h1>Live OCR Scanner</h1>
    <div id="videoWrapper" style="position: relative; display: inline-block;">
        <video id="video" autoplay playsinline></video>
    </div>
    <canvas id="processedCanvas" width="480" height="200"></canvas>
    <canvas id="internalCanvas" width="480" height="200"></canvas>
    <textarea id="output" placeholder="Recognized text appears here..."></textarea>
    <div class="buttons">
        <button id="flashBtn">Toggle Flashlight</button>
        <button id="toggleOcrBtn">Start OCR</button>
        <button id="copyBtn">Copy</button>
        <button id="opencvToggleBtn">Use OpenCV: On</button>
    </div>

    <script>
        const video = document.getElementById('video');
        const processedCanvas = document.getElementById('processedCanvas');
        const internalCanvas = document.getElementById('internalCanvas');
        const processedCtx = processedCanvas.getContext('2d');
        const internalCtx = internalCanvas.getContext('2d');
        const output = document.getElementById('output');
        const toggleOcrBtn = document.getElementById('toggleOcrBtn');

        const intervalMs = 3000;

        let ocrInterval = null;
        let videoTrack = null;
        let flashOn = false;
        let useOpenCV = true;

        function getCropRect() {
            const cropWidth = 480;
            const cropHeight = 200;
            const sx = (video.videoWidth - cropWidth) * 0.50;
            const sy = (video.videoHeight - cropHeight) * 0.50;

            return { sx, sy, cropWidth, cropHeight };
        }

        function createOverlay() {
            const existing = document.getElementById('cropOverlay');
            if (existing) existing.remove();

            const { sx, sy, cropWidth, cropHeight } = getCropRect();

            const scaleX = video.clientWidth / video.videoWidth;
            const scaleY = video.clientHeight / video.videoHeight;
            const overlay = document.createElement('div');
            overlay.id = 'cropOverlay';
            overlay.style.position = 'absolute';
            overlay.style.border = '2px solid red';
            overlay.style.width = `${cropWidth * scaleX}px`;
            overlay.style.height = `${cropHeight * scaleY}px`;
            const rect = video.getBoundingClientRect();
            overlay.style.left = `${sx * scaleX + rect.left}px`;
            overlay.style.top = `${sy * scaleY + rect.top}px`;
            overlay.style.pointerEvents = 'none';
            overlay.style.zIndex = '10';
            document.getElementById('videoWrapper').appendChild(overlay);

        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                });
                video.srcObject = stream;
                videoTrack = stream.getVideoTracks()[0];

                // Wait until video has dimensions
                await new Promise(resolve => {
                    video.onloadedmetadata = () => resolve();
                });

                createOverlay(); // ✅
            } catch (err) {
                alert('Camera access denied: ' + err.message);
            }
        }

        async function performOCR() {
            const { sx, sy, cropWidth, cropHeight } = getCropRect();
            createOverlay();

            //Draw cropped image onto internal canvas
            internalCtx.drawImage(video, sx, sy, cropWidth, cropHeight, 0, 0, internalCanvas.width, internalCanvas.height);
            await new Promise(resolve => setTimeout(resolve, 50));

            if (useOpenCV) {
                //cv is a global object exposed by the OpenCV.js library
                if (!cv || typeof cv.imread !== 'function') {
                    // OpenCV not ready yet — wait
                    await new Promise(resolve => {
                        const check = () => {
                            if (cv && typeof cv.imread === 'function') {
                                resolve();
                            } else {
                                setTimeout(check, 50);
                            }
                        };
                        check();
                    });
                }

                const src = cv.imread(internalCanvas);
                let gray = new cv.Mat();
                let dst = new cv.Mat();

                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                cv.adaptiveThreshold(gray, dst, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);
                if (dst.cols !== internalCanvas.width || dst.rows !== internalCanvas.height) {
                    cv.resize(dst, dst, new cv.Size(internalCanvas.width, internalCanvas.height));
                }

                // Display processed image
                cv.imshow('processedCanvas', dst);

                // Push to canvas for Tesseract
                const imgData = processedCtx.createImageData(processedCanvas.width, processedCanvas.height);
                const pixelCount = Math.min(dst.data.length, processedCanvas.width * processedCanvas.height);
                for (let i = 0; i < pixelCount; i++) {
                    const val = dst.data[i];
                    imgData.data[i * 4] = val;
                    imgData.data[i * 4 + 1] = val;
                    imgData.data[i * 4 + 2] = val;
                    imgData.data[i * 4 + 3] = 255;
                }
                processedCtx.putImageData(imgData, 0, 0);

                src.delete(); gray.delete(); dst.delete();
            } else {
                // Binarization
                const imageData = internalCtx.getImageData(0, 0, internalCanvas.width, internalCanvas.height);
                const data = imageData.data;
                for (let i = 0; i < data.length; i += 4) {
                    const avg = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
                    const val = avg > 180 ? 255 : 0;
                    data[i] = data[i + 1] = data[i + 2] = val;
                }
                processedCtx.putImageData(imageData, 0, 0);

            }

            // OCR
            const { data: { text } } = await Tesseract.recognize(processedCanvas, 'eng', {
                langPath: 'https://tessdata.projectnaptha.com/4.0.0_best',
            });
            if (text.trim()) {
                output.value = text.trim();
            }
        }



        async function toggleOCR() {
            if (ocrInterval) {
                clearInterval(ocrInterval);
                ocrInterval = null;
                toggleOcrBtn.textContent = 'Start OCR';
                if (flashOn && videoTrack) {
                    try {
                        await videoTrack.applyConstraints({ advanced: [{ torch: false }] });
                        flashOn = false;
                    } catch (err) {
                        console.warn('Failed to turn off flashlight:', err);
                    }
                }

                // Stop video stream
                if (video.srcObject) {
                    video.srcObject.getTracks().forEach(track => track.stop());
                    video.srcObject = null;
                }
                videoTrack = null;
            } else {
                await startCamera();
                performOCR();
                ocrInterval = setInterval(performOCR, intervalMs);
                toggleOcrBtn.textContent = 'Stop OCR';
            }
        }

        //ADD EVENT LISTENERS       

        const opencvToggleBtn = document.getElementById('opencvToggleBtn');
        opencvToggleBtn.addEventListener('click', () => {
            useOpenCV = !useOpenCV;
            opencvToggleBtn.textContent = `Use OpenCV: ${useOpenCV ? 'On' : 'Off'}`;
        });

        const copyBtn = document.getElementById('copyBtn');
        copyBtn.addEventListener('click', () => {
            const originalText = output.value;
            navigator.clipboard.writeText(originalText)
                .then(() => {
                    output.value = 'Text copied!';
                    setTimeout(() => {
                        output.value = originalText;
                    }, 1500); // restore after 1.5s
                })
                .catch(err => {
                    output.value = 'Copy failed: ' + err;
                });
        });

        const flashBtn = document.getElementById('flashBtn');
        flashBtn.addEventListener('click', async () => {
            if (!videoTrack) return alert('Camera not initialized');

            const capabilities = videoTrack.getCapabilities?.();
            if (!capabilities?.torch) return alert('Flashlight not supported on this device');

            try {
                flashOn = !flashOn;
                await videoTrack.applyConstraints({ advanced: [{ torch: flashOn }] });
            } catch (err) {
                alert('Failed to toggle flashlight: ' + err.message);
            }
        });


        toggleOcrBtn.addEventListener('click', toggleOCR);

    </script>
</body>

</html>